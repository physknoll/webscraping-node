# ğŸŒ **Website Crawler and Summarization Framework**

## ğŸ“‹ **Overview**
This Node.js framework leverages the **LLM Scraper** for extracting structured data from websites.

## âœ¨ **Features**
1. ğŸ•·ï¸ **LLM Scraper Integration**: Extract structured data using schemas
2. ğŸ¤– **Bee Agent Framework**: Automate complex workflows
3. ğŸŒ **Dynamic Web Crawling**: Handle dynamic websites

## ğŸ› ï¸ **Technologies Used**
- ğŸ’š **Node.js**: Backend runtime
- ğŸ“˜ **TypeScript**: Type safety
- ğŸš€ **Express.js**: API framework
- ğŸ—„ï¸ **MongoDB**: Database
- ğŸ¤– **OpenAI**: LLM integration

## ğŸš€ **Installation**

### Prerequisites
- ğŸ“¦ Node.js >= 16
- ğŸ—„ï¸ MongoDB Atlas account
- ğŸ”‘ OpenAI API key

### Quick Start
```bash
git clone https://github.com/physknoll/webscraping-node.git
cd webscraping-node
npm install
```

## âš™ï¸ **Configuration**

Create a `.env` file:
```env
MONGO_URI=your_mongodb_uri
OPENAI_API_KEY=your_openai_key
OPENAI_ORGANIZATION_ID=your_org_id
PORT=3000
```

## ğŸ“± **Usage**

```bash
# Development
npm run dev

# Production
npm start
```

## ğŸ¤ **Contributing**
1. ğŸ´ Fork
2. ğŸŒ¿ Branch
3. ğŸ¯ Pull Request